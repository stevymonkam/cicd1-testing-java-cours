# DevOps 2-4 ans: Ã‰quipe de 3 + Lead Senior

## Structure de l'Ã©quipe

**Lead DevOps Senior (6-8 ans)**
- DÃ©finit l'architecture
- Prend les dÃ©cisions stratÃ©giques
- Valide les pull requests
- Mentoring

**DevOps Mid-level (2-4 ans) â† VOUS**
- ExÃ©cution autonome
- Design de solutions moyennes
- Support technique principal

**DevOps Junior (0-2 ans)**
- TÃ¢ches simples guidÃ©es
- Apprentissage

## Vos responsabilitÃ©s concrÃ¨tes

### Docker
- CrÃ©er/optimiser des Dockerfiles pour applications
- Debugging images : taille, sÃ©curitÃ©, performances
- Registry management : nettoyer les vieilles images, tagging
- Tests docker-compose en dÃ©veloppement
- RÃ©soudre les problÃ¨mes de build/push

### Kubernetes
- DÃ©ploiements quotidiens : pods, services, ingress
- Debugging avancÃ© : logs, exec, port-forward, describe
- Networking : services, network policies, ingress
- Troubleshooting : CrashLoopBackOff, resource limits
- Scaling : HPA, rÃ©plicas, resource management
- SÃ©curitÃ© : RBAC, secrets, security policies

### Helm
- CrÃ©er des Charts simples Ã  complexes
- Adapter Charts existants pour nouvelles apps
- Templating : values.yaml, conditions, loops
- Testing : lint, dry-run, validation
- Versionning des Charts
- Helm hooks : tests, pre/post dÃ©ploiement

### Jenkins
- CrÃ©er des pipelines declaratives et scriptÃ©es
- CI/CD complet : build, test, push, deploy
- Kubernetes plugin : agents dynamiques
- IntÃ©grations : SonarQube, Docker, Helm, ArgoCD
- Credentials management : secrets, tokens
- Debugging : logs pipelines, stages Ã©chouÃ©s

### ArgoCD (GitOps)
- CrÃ©er des Applications ArgoCD
- Configurer les sync policies
- Debugging sync issues
- Gestion des dÃ©pendances : sync waves
- AppProjects et RBAC ArgoCD

### Prometheus & Grafana
- CrÃ©er des dashboards personnalisÃ©s
- Configurer les alertes
- PromQL queries : mÃ©triques pod, service, node
- Troubleshoot : metriques manquantes, collecte
- ServiceMonitors pour Prometheus

## Distribution du travail avec votre Lead

### ResponsabilitÃ©s du Lead Senior
- Approuver architectures
- DÃ©cider technologies/versions
- Valider designs complexes
- Escalation production
- Planning stratÃ©gique
- Code reviews stratÃ©giques

### Ce que vous faites SANS demander
- CrÃ©er une pipeline Jenkins pour une nouvelle app
- Adapter un Helm Chart existant
- DÃ©boguer un pod en crash
- CrÃ©er des dashboards Grafana
- Configurer des alertes Prometheus
- DÃ©ployer en dev/staging

### Ce que vous faites AVEC validation Lead
- Decisions architecturales majeures
- Changements de cluster
- Modifications de sÃ©curitÃ© RBAC
- DÃ©ploiements en production complexes
- Modifications Kubernetes critiques

### Escalade au Lead (obligatoire)
- Incidents critiques production
- Perte de donnÃ©es potentielle
- Changements irrÃ©versibles
- ProblÃ¨mes non rÃ©solus en 1h
- Questions de sÃ©curitÃ©

## Semaine type : rÃ©partition

### Lundi
- Daily standup (15 min)
- CrÃ©er une pipeline Jenkins pour la nouvelle app "payment-service" (2h)
- Adapter un Helm Chart existant (1.5h)
- Review code d'un collÃ¨gue (1h)
- Support dÃ©veloppeurs (30 min)

### Mardi
- DÃ©boguer incident : Pod CrashLoopBackOff en staging (2h)
  - Voir les logs
  - VÃ©rifier les resources
  - Identifier la cause
  - Corriger et redÃ©ployer
- Optimiser un deployment : resource limits incorrects (1.5h)
- Mettre Ã  jour des Charts : nouvelles versions (1h)
- Monitoring ad-hoc (30 min)

### Mercredi
- CrÃ©er des dashboards Grafana : monitoring microservices (2h)
- Configurer des alertes Prometheus : sur-consommation CPU/RAM (1.5h)
- DÃ©ployer en staging : version candidate production (1h)
- Pair programming avec junior (1h)

### Jeudi
- VÃ©rifier ArgoCD : synchronisation des apps (30 min)
- DÃ©boguer sync issue : dÃ©pendances manquantes (1h)
- Teste de performance : scaling sous charge (1.5h)
- Documenter un runbook : procÃ©dure de redÃ©marrage pod (1h)
- Valider la pipeline avec le lead avant prod (30 min)

### Vendredi
- Script d'automatisation : cleanup docker registry (1h)
- AmÃ©lioration continue : proposition d'optimisation (1.5h)
- Documentation/knowledge sharing (1h)
- DÃ©ploiement production hebdo (1.5h)
- Retrospective Ã©quipe (30 min)

## TÃ¢ches quotidiennes vs. exceptionnelles

### Quotidiennes (40% du temps)
- Support dÃ©veloppeurs
- Debugging pods/services
- Monitoring dashboards
- VÃ©rifier les dÃ©ploiements
- RÃ©pondre aux tickets

### RÃ©guliÃ¨res (30% du temps)
- CrÃ©er pipelines Jenkins
- Adapter/optimiser Helm Charts
- Configurer alertes
- DÃ©ploiements planifiÃ©s

### Occasionnelles (20% du temps)
- Incidents majeurs
- Architecture improvements
- Scripts d'automatisation
- Formation/documentation

### Rares (10% du temps)
- DÃ©cisions stratÃ©giques
- Migrations/changements majeurs
- Escalade production

## Ce que vous NE faites PAS
- DÃ©cisions d'infrastructure au niveau cluster
- Budget/coÃ»ts cloud (lead fait Ã§a)
- NÃ©gociations vendors
- On-call niveau 3 (escalation finale)
- Security audits complets
- Disaster recovery planning seul
- Architecture multi-rÃ©gion
- DÃ©cisions stratÃ©giques long terme

## Autonomie attendue Ã  2-4 ans

| Situation | Votre action |
|-----------|--------------|
| Pipeline Ã©choue en dev | Debugger, corriger, relancer |
| Pod crash en staging | Investigation complÃ¨te, rÃ©soudre |
| Question dev sur Kubernetes | Expliquer et aider |
| Nouvelle app Ã  dÃ©ployer | Design du chart, crÃ©ation pipeline |
| Alert Prometheus sensibilitÃ© | Ajuster sans demander |
| ProblÃ¨me production | Essayer rapidement (5-10 min), puis escalade lead |
| Choix architecture simple | DÃ©cider et implÃ©menter |
| Choix architecture complexe | Proposer au lead, discussion |

## Progression vers Senior (4+ ans)

Pour passer Ã  Senior dans 1-2 ans:
- Mentorer le junior rÃ©guliÃ¨rement
- Prendre des dÃ©cisions architecturales plus souvent
- Valider les solutions des autres
- Proposer des amÃ©liorations stratÃ©giques
- ÃŠtre autonome 95% du temps sur production
- DÃ©boguer des problÃ¨mes trÃ¨s complexes
- Documenter et partager les best practices
- ÃŠtre on-call niveau 2 (escalade intermÃ©diaire)

---

# Workflow rÃ©el: Kubernetes + Helm automatisÃ© dans Jenkins

## Le malentendu courant

**Croyance fausse:**
"Jenkins dÃ©ploie automatiquement avec Helm, donc les DevOps n'ont rien Ã  faire sur Kubernetes/Helm"

**RÃ©alitÃ©:**
Jenkins automatise le processus, mais vous gÃ©rez, debuggez, optimisez Kubernetes et Helm constamment.

## Architecture rÃ©elle en entreprise

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Git Repository                           â”‚
â”‚  (Code app + Helm Charts + Jenkinsfile)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ (Webhook: push sur main)
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Jenkins Pipeline                           â”‚
â”‚  Stage 1: Build (Maven/Go/Python)                               â”‚
â”‚  Stage 2: Test                                                   â”‚
â”‚  Stage 3: Docker Build & Push                                    â”‚
â”‚  Stage 4: â­ HELM DEPLOY (automatisÃ©)                            â”‚
â”‚  Stage 5: Smoke Tests                                            â”‚
â”‚  Stage 6: Notify                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ (helm upgrade --install ...)
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Kubernetes Cluster (Dev/Staging/Prod)              â”‚
â”‚  â”œâ”€ Deployments                                                  â”‚
â”‚  â”œâ”€ Services                                                     â”‚
â”‚  â”œâ”€ Ingress                                                      â”‚
â”‚  â”œâ”€ ConfigMaps/Secrets                                           â”‚
â”‚  â”œâ”€ HPA (Horizontal Pod Autoscaler)                              â”‚
â”‚  â””â”€ PVC (Persistent Volumes)                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DevOps: Monitoring, Debugging, Optimisation, Gestion           â”‚
â”‚  â”œâ”€ Grafana/Prometheus (alertes, dashboards)                     â”‚
â”‚  â”œâ”€ Logs (ELK, Loki)                                             â”‚
â”‚  â”œâ”€ kubectl debugging (logs, exec, describe)                     â”‚
â”‚  â””â”€ Helm Chart maintenance                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Scenario rÃ©el: DÃ©ploiement d'une app

### Timeline

**Jour 1 - Avant le dÃ©ploiement**

```
9h00  Dev finit la feature, crÃ©e un commit
      â†’ Pousse sur git dans branche "feature/payment-v2"

9h30  Pull Request crÃ©Ã©e
      â†’ Pipeline Jenkins dÃ©marre AUTOMATIQUEMENT
      
10h00 Jenkins a fini les tests
      â†’ Code review par Dev Lead + DevOps Lead
      
10h30 PR approuvÃ©e, merge sur "main"
      â†’ Webhook Jenkins dÃ©clenchÃ©
```

**10h45 - Jenkins pipeline dÃ©marre (AUTOMATISÃ‰)**

```groovy
// Stage 1-3: Build + Test + Docker Build
âœ… Maven build (3 min)
âœ… Tests unitaires (2 min)
âœ… Docker build & push (2 min)
   â†’ Image: registry.company.com/payment-service:abc123

// Stage 4: HELM DEPLOY (C'EST ICI QUE VOUS INTERVENEZ)
helm upgrade --install payment-service ./helm/payment-service \
  --namespace production \
  --values values-prod.yaml \
  --set image.tag=abc123 \
  --wait \
  --timeout 10m

âœ… Helm chart installÃ© (2 min)

// Stage 5: Smoke Tests
âœ… VÃ©rifier les pods (1 min)

// RÃ©sultat final
âœ… DEPLOYMENT SUCCESS Ã  11h02
```

Mais en rÃ©alitÃ©, Jenkins a juste exÃ©cutÃ© des commandes.
**Le vrai travail commence aprÃ¨s...**

## Ce que vous FAITES VRAIMENT aprÃ¨s le dÃ©ploiement automatisÃ©

### 1. Pendant le dÃ©ploiement (Jenkins run en cours)

Vous regardez activement :

```bash
# Terminal 1: Watcher les pods
kubectl get pods -n production -l app=payment-service -w

# Terminal 2: Voir les logs en temps rÃ©el
kubectl logs -n production -l app=payment-service -f

# Terminal 3: Avoir Grafana ouvert sur le dashboard
# Regarder CPU, Memory, Request rate pendant le rollout
```

**Pourquoi?** Parce que mÃªme si Jenkins dÃ©ploie, les choses peuvent Ã©chouer silencieusement:

- Pod dÃ©marre mais crash aprÃ¨s 30 secondes
- Pas assez de ressources â†’ OOMKilled
- Database connection Ã©choue â†’ CrashLoopBackOff
- Image n'existe pas â†’ ImagePullBackOff

**Votre rÃ´le: DÃ©tecter et corriger en direct**

```bash
# âŒ ProblÃ¨me dÃ©tectÃ©: Pod crash
kubectl logs -n production payment-service-xyz-123

# Output:
# Error: Cannot connect to database: Connection refused

# ğŸ” Investigation:
kubectl describe pod payment-service-xyz-123 -n production

# Output:
# Events:
#   - Normal   Created    2m
#   - Normal   Started    2m
#   - Warning  BackOff    1m    (back-off restarting failed container)

# âœ… Solution: Les variables d'env ne sont pas passÃ©es correctement
# VÃ©rifier le Helm Chart
kubectl get deployment payment-service -n production -o yaml | grep env

# Correction: Edit values-prod.yaml ou patch direct
kubectl set env deployment/payment-service \
  DB_HOST=postgres-prod.internal \
  DB_PORT=5432 \
  -n production

# RedÃ©marrer
kubectl rollout restart deployment/payment-service -n production
```

### 2. AprÃ¨s le dÃ©ploiement (Post-deployment)

**Les heures qui suivent: Surveillance active**

```
11h15 - Helm a dÃ©ployÃ©, pods en running
       Vous: Regarder les logs pour erreurs
       
11h30 - VÃ©rifier Grafana
       Vous: Request rate normal? Error rate 0%? 
       
11h45 - Tester les endpoints critiques
       You: 
       curl https://api.company.com/payments/health
       curl https://api.company.com/payments/list?limit=10
       
12h00 - VÃ©rifier les alertes Prometheus
       Vous: Aucune alerte dÃ©clenchÃ©e?
       
12h30 - Tout semble bon
       Vous: CrÃ©er un ticket pour documenter
       
14h00 - Re-check les logs (4h aprÃ¨s dÃ©ploiement)
       Vous: Aucune erreur intermittente?
```

### 3. Entre les dÃ©ploiements (Maintenance quotidienne)

Vous allez faire BEAUCOUP de travail en Kubernetes/Helm

#### A. Debugging et troubleshooting

```bash
# Lundi matin: Incident Slack
# "@devops Service payment est lent en production"

# Ã‰tape 1: VÃ©rifier les pods
kubectl get pods -n production | grep payment

# Output:
# payment-service-xyz    1/1    Running    0    3d
# payment-service-abc    1/1    Running    0    3d
# payment-service-def    0/1    CrashLoop  4    5m  âš ï¸

# Ã‰tape 2: Voir les logs du pod crash
kubectl logs payment-service-def -n production --tail=50

# Output:
# Exception: OutOfMemoryError

# Ã‰tape 3: VÃ©rifier les resources allouÃ©es
kubectl get deployment payment-service -n production -o jsonpath='{.spec.template.spec.containers[0].resources}'

# Output:
# {"limits":{"memory":"512Mi"},"requests":{"memory":"256Mi"}}

# ProblÃ¨me: Memory limit trop basse!

# Ã‰tape 4: Corriger le Helm Chart
vim helm/payment-service/values-prod.yaml

# Changer:
# resources:
#   limits:
#     memory: "512Mi"   â†’ "2Gi"
#   requests:
#     memory: "256Mi"   â†’ "1Gi"

# Ã‰tape 5: RedÃ©ployer avec les valeurs corrigÃ©es
helm upgrade payment-service ./helm/payment-service \
  --namespace production \
  --values values-prod.yaml \
  --wait

# Ã‰tape 6: VÃ©rifier
kubectl get pods -n production | grep payment
# Tous en 1/1 Running âœ…
```

#### B. Optimisation des Helm Charts

```bash
# Jeudi aprÃ¨s-midi: AmÃ©lioration continue

# ProblÃ¨me identifiÃ©: Helm chart manque de health checks
# Solution: Ã‰diter le Helm Chart

vim helm/payment-service/templates/deployment.yaml

# Ajouter:
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 60
  periodSeconds: 10

readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 5

# Tester en dev d'abord
helm upgrade payment-service ./helm/payment-service \
  --namespace dev \
  --values values-dev.yaml \
  --dry-run --debug

# Puis en prod
helm upgrade payment-service ./helm/payment-service \
  --namespace production \
  --values values-prod.yaml
```

#### C. GÃ©rer les ressources et le scaling

```bash
# Lundi: HPA dÃ©clenchÃ©e, CPU Ã  85%
# VÃ©rifier si c'est normal ou si besoin d'ajuster

kubectl top pods -n production -l app=payment-service

# Output:
# payment-service-1   450m   800Mi    (82% CPU)
# payment-service-2   460m   750Mi    (84% CPU)
# payment-service-3   440m   720Mi    (79% CPU)
# payment-service-4   470m   760Mi    (85% CPU) â† HPA vient d'ajouter ce pod

# DÃ©cision: C'est OK (charge temporaire)
# Mais si Ã§a persiste, augmenter les limits dans Helm

helm get values payment-service -n production | grep cpu

# VÃ©rifier si besoin d'ajuster le CPU
# resources.limits.cpu: 600m â†’ augmenter Ã  800m?
```

#### D. Configurer les Helm Charts pour chaque environnement

```bash
# Dev: Peu de ressources
values-dev.yaml:
  replicas: 1
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
  autoscaling.enabled: false

# Staging: Configuration test
values-staging.yaml:
  replicas: 2
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
  autoscaling.enabled: false

# Prod: Haute disponibilitÃ©
values-prod.yaml:
  replicas: 5
  resources:
    limits:
      cpu: 1000m
      memory: 2Gi
  autoscaling.enabled: true
  minReplicas: 5
  maxReplicas: 20
```

## RÃ©partition rÃ©elle du travail

### Jenkins (30% du temps)
- CrÃ©er/maintenir les Jenkinsfiles
- Fixer les pipelines cassÃ©es
- Ajouter des stages (tests, security scans)
- Debug des erreurs de build
- Les dÃ©ploiements eux-mÃªmes: ~5 minutes d'exÃ©cution automatique

### Kubernetes (40% du temps)
- Debugging pods en crash
- VÃ©rifier les logs en production
- Troubleshooting connectivity
- Watcher les dÃ©ploiements en temps rÃ©el
- VÃ©rifier les resources
- GÃ©rer les persistent volumes
- Troubleshooting networking

### Helm (20% du temps)
- CrÃ©er/adapter des Charts
- GÃ©rer les values par environnement
- Tester les Charts (helm lint, dry-run)
- Optimiser les configurations
- Versioning des Charts

### Monitoring (10% du temps)
- CrÃ©er des dashboards
- Configurer des alertes
- VÃ©rifier les mÃ©triques pendant les dÃ©ploiements

## Exemple: Une journÃ©e complÃ¨te avec Jenkins automatisÃ©

```
9h00  Daily standup
      Vous: "Hier j'ai dÃ©ployÃ© payment-service v2.1.0
            Aujourd'hui je dois debugger le pod redis qui crash en prod"

9h15  Incident Slack
      "@devops Le dashboard n'affiche plus les commandes"
      
      âœ Vous investigez:
      kubectl get pods -n production | grep dashboard
      kubectl logs dashboard-xyz -n production --tail=100
      kubectl describe pod dashboard-xyz -n production
      
      âœ ProblÃ¨me: Services n'est pas accessible
      kubectl get svc dashboard -n production
      kubectl get endpoints dashboard -n production
      
      âœ Solution: RedÃ©marrer le service
      kubectl rollout restart deployment/dashboard -n production
      
      âœ VÃ©rifier:
      curl -I http://dashboard-service:8080

10h00 Jenkins pipeline auto-dÃ©ploie la nouvelle version de user-service
      
      âœ Vous regardez en direct:
      kubectl get pods -n production -l app=user-service -w
      kubectl logs -f -n production -l app=user-service
      
      âœ ProblÃ¨me dÃ©tectÃ©: Pod crash aprÃ¨s 20 secondes
      kubectl logs -n production user-service-abc
      
      Output: "Error: Config map 'user-service-config' not found"
      
      âœ C'est vous qui allez corriger:
      kubectl get cm -n production | grep user-service
      # ConfigMap manquante, elle doit Ãªtre crÃ©Ã©e par le Helm chart
      
      âœ VÃ©rifier le Helm chart:
      cat helm/user-service/templates/configmap.yaml
      
      âœ ProblÃ¨me: ConfigMap n'est pas crÃ©Ã©e correctement
      helm get manifest user-service -n production
      
      âœ Fix: Ã‰diter le Helm chart ou crÃ©er le ConfigMap manuellement
      kubectl create configmap user-service-config \
        --from-literal=DB_HOST=postgres \
        --namespace production
      
      âœ RedÃ©ployer:
      helm upgrade user-service ./helm/user-service \
        --namespace production \
        --wait

11h30 DÃ©boguer le problÃ¨me redis qui crash (de ce matin)
      
      âœ kubectl logs -n production redis-master
      Output: "Connection timeout: Too many connections (1000 max)"
      
      âœ Problem: Limite de connexions atteinte
      âœ Solution: Augmenter les limites dans Helm
      
      vim helm/user-service/values-prod.yaml
      # redis.maxclients: 1000 â†’ 2000
      
      helm upgrade user-service ./helm/user-service \
        --namespace production \
        --values values-prod.yaml

12h00 Lunch

13h00 Code review d'un collÃ¨gue
      âœ Review le Helm chart qu'il a crÃ©Ã©
      âœ Commentaires: "Resource limits manquent, HPA pas configurÃ©e"

14h00 CrÃ©er les dashboards Grafana pour les nouvelles mÃ©triques
      âœ PromQL query: rate(http_requests_total[5m])
      âœ Ajouter une alerte si error_rate > 5%

15h00 Tester un nouveau Helm chart en dev
      
      helm install test-app ./helm/test-app \
        --namespace dev \
        --values values-dev.yaml \
        --dry-run --debug
      
      âœ Corriger les erreurs
      âœ Installer pour de vrai
      âœ Tester en manual

16h00 Documenter le runbook pour le problÃ¨me redis
      âœ CrÃ©er sur Confluence
      âœ "Que faire si redis-master crash"

17h00 VÃ©rifier que les dÃ©ploiements de la journÃ©e se portent bien
      âœ Regarder les logs one more time
      âœ VÃ©rifier Grafana
```

## Le point clÃ©

**Jenkins automatise le processus de dÃ©ploiement (la commande elle-mÃªme)**

Mais vous gÃ©rez:

- âœ… **Avant:** CrÃ©er les Charts, Ã©crire les Jenkinsfiles
- âœ… **Pendant:** Watcher les logs, dÃ©tecter les crashs
- âœ… **AprÃ¨s:** Debugger, corriger, optimiser
- âœ… **Entre:** Maintenance, amÃ©lioration, troubleshooting

**C'est pour Ã§a que vous Ãªtes payÃ©** - pas pour lancer "helm install", mais pour gÃ©rer tout ce qui peut mal tourner.

## Donc en rÃ©sumÃ©

| ActivitÃ© | AutomatisÃ©e? | Votre rÃ´le |
|----------|--------------|------------|
| Push code â†’ Git | âœ… Auto | - |
| Jenkins dÃ©clenchÃ© | âœ… Auto | - |
| Build/Test/Docker | âœ… Auto | CrÃ©er Jenkinsfile |
| Helm deploy | âœ… Auto | Watcher, corriger si Ã©choue |
| Pods dÃ©marre | âœ… Auto | VÃ©rifier les logs |
| Service accessible | âŒ Auto | Vous debuggez |
| Monitoring actif | âŒ Auto | Vous regardez Grafana |
| Alerts config | âŒ Auto | Vous crÃ©ez les rÃ¨gles |
| Logs analysÃ©s | âŒ Auto | Vous enquÃªtez |
| Performance OK | âŒ Auto | Vous optimisez Helm Chart |